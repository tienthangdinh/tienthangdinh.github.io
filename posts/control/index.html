<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-07-07">

<title>From Control to Model-based Learning – Bánh cuốn nguội</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bánh cuốn nguội</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Stalk me</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">From Control to Model-based Learning</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Control Theory</div>
                <div class="quarto-category">Optimization</div>
                <div class="quarto-category">Dynamics</div>
                <div class="quarto-category">Model-based Learning</div>
                <div class="quarto-category">Reinforcement Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 7, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#pid-controller-and-its-problem" id="toc-pid-controller-and-its-problem" class="nav-link active" data-scroll-target="#pid-controller-and-its-problem">PID Controller and its Problem</a>
  <ul class="collapse">
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">Mathematical Formulation</a></li>
  <li><a href="#but-why-p-i-and-d-why-not-just-use-the-current-error" id="toc-but-why-p-i-and-d-why-not-just-use-the-current-error" class="nav-link" data-scroll-target="#but-why-p-i-and-d-why-not-just-use-the-current-error">But Why P, I, and D? Why not just use the current error?</a>
  <ul class="collapse">
  <li><a href="#the-proportional-p-term-present" id="toc-the-proportional-p-term-present" class="nav-link" data-scroll-target="#the-proportional-p-term-present">The Proportional (P) Term: Present</a></li>
  <li><a href="#the-integral-i-term-gradual-push-effort" id="toc-the-integral-i-term-gradual-push-effort" class="nav-link" data-scroll-target="#the-integral-i-term-gradual-push-effort">The Integral (I) Term: Gradual Push Effort</a></li>
  <li><a href="#the-derivative-d-term-anticipation-and-damping" id="toc-the-derivative-d-term-anticipation-and-damping" class="nav-link" data-scroll-target="#the-derivative-d-term-anticipation-and-damping">The Derivative (D) Term: Anticipation and Damping</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#the-lti-system-dynamics-the-state-space-model" id="toc-the-lti-system-dynamics-the-state-space-model" class="nav-link" data-scroll-target="#the-lti-system-dynamics-the-state-space-model">The LTI System Dynamics: The State-Space Model</a>
  <ul class="collapse">
  <li><a href="#example-lti-system-the-mass-spring-damper" id="toc-example-lti-system-the-mass-spring-damper" class="nav-link" data-scroll-target="#example-lti-system-the-mass-spring-damper">Example LTI System: The Mass-Spring-Damper</a></li>
  </ul></li>
  <li><a href="#the-linear-quadratic-regulator-lqr---model-hint-to-optimal-control" id="toc-the-linear-quadratic-regulator-lqr---model-hint-to-optimal-control" class="nav-link" data-scroll-target="#the-linear-quadratic-regulator-lqr---model-hint-to-optimal-control">The Linear Quadratic Regulator (LQR) - Model-hint to Optimal Control</a>
  <ul class="collapse">
  <li><a href="#formulate-into-integral-of-terms-using-x-and-u" id="toc-formulate-into-integral-of-terms-using-x-and-u" class="nav-link" data-scroll-target="#formulate-into-integral-of-terms-using-x-and-u">Formulate into integral of terms using x and u</a>
  <ul class="collapse">
  <li><a href="#important-part" id="toc-important-part" class="nav-link" data-scroll-target="#important-part">Important part</a></li>
  </ul></li>
  <li><a href="#derivation-of-linear-optimal-control-u--kx-and-quadratic-value-function-vxxt-px" id="toc-derivation-of-linear-optimal-control-u--kx-and-quadratic-value-function-vxxt-px" class="nav-link" data-scroll-target="#derivation-of-linear-optimal-control-u--kx-and-quadratic-value-function-vxxt-px">Derivation of Linear Optimal Control (<span class="math inline">\(u^* = -Kx\)</span>) and Quadratic Value Function (<span class="math inline">\(V(x)=x^T Px\)</span>)</a>
  <ul class="collapse">
  <li><a href="#bellman-optimality---the-value-function-cost-to-go" id="toc-bellman-optimality---the-value-function-cost-to-go" class="nav-link" data-scroll-target="#bellman-optimality---the-value-function-cost-to-go">Bellman Optimality -&gt; The Value Function (Cost-to-Go):</a></li>
  <li><a href="#deriving-u--kx" id="toc-deriving-u--kx" class="nav-link" data-scroll-target="#deriving-u--kx">Deriving <span class="math inline">\(u^* = -Kx\)</span></a></li>
  <li><a href="#deriving-vxxt-px" id="toc-deriving-vxxt-px" class="nav-link" data-scroll-target="#deriving-vxxt-px">Deriving <span class="math inline">\(V(x)=x^T Px\)</span></a></li>
  <li><a href="#deriving-are" id="toc-deriving-are" class="nav-link" data-scroll-target="#deriving-are">Deriving ARE</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#mpc" id="toc-mpc" class="nav-link" data-scroll-target="#mpc">MPC</a>
  <ul class="collapse">
  <li><a href="#transformation-to-a-standard-quadratic-program-qp" id="toc-transformation-to-a-standard-quadratic-program-qp" class="nav-link" data-scroll-target="#transformation-to-a-standard-quadratic-program-qp">Transformation to a Standard Quadratic Program (QP)</a>
  <ul class="collapse">
  <li><a href="#prediction-of-future-states" id="toc-prediction-of-future-states" class="nav-link" data-scroll-target="#prediction-of-future-states">1. Prediction of Future States:</a></li>
  <li><a href="#substituting-into-the-objective-function" id="toc-substituting-into-the-objective-function" class="nav-link" data-scroll-target="#substituting-into-the-objective-function">2. Substituting into the Objective Function:</a></li>
  <li><a href="#substituting-into-constraints" id="toc-substituting-into-constraints" class="nav-link" data-scroll-target="#substituting-into-constraints">3. Substituting into Constraints:</a></li>
  </ul></li>
  <li><a href="#the-result-a-standard-qp-form" id="toc-the-result-a-standard-qp-form" class="nav-link" data-scroll-target="#the-result-a-standard-qp-form">The Result: A Standard QP Form</a></li>
  <li><a href="#solutions-for-mpc-quadratic-programming-qp-solvers" id="toc-solutions-for-mpc-quadratic-programming-qp-solvers" class="nav-link" data-scroll-target="#solutions-for-mpc-quadratic-programming-qp-solvers">Solutions for MPC (Quadratic Programming (QP) Solvers)</a></li>
  <li><a href="#derivation" id="toc-derivation" class="nav-link" data-scroll-target="#derivation">Derivation</a>
  <ul class="collapse">
  <li><a href="#state-prediction-in-compact-matrix-form" id="toc-state-prediction-in-compact-matrix-form" class="nav-link" data-scroll-target="#state-prediction-in-compact-matrix-form">State Prediction in Compact Matrix Form</a></li>
  <li><a href="#substituting-into-the-objective-function-deriving-h-g-j_const" id="toc-substituting-into-the-objective-function-deriving-h-g-j_const" class="nav-link" data-scroll-target="#substituting-into-the-objective-function-deriving-h-g-j_const">Substituting into the Objective Function (Deriving H, G, J_const)</a></li>
  <li><a href="#but-why-do-we-need-to-transform-the-cost-function-into-separated-linear-quadratic-and-jconst-term" id="toc-but-why-do-we-need-to-transform-the-cost-function-into-separated-linear-quadratic-and-jconst-term" class="nav-link" data-scroll-target="#but-why-do-we-need-to-transform-the-cost-function-into-separated-linear-quadratic-and-jconst-term">But why do we need to transform the cost function into separated linear, quadratic and Jconst term?</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="pid-controller-and-its-problem" class="level1">
<h1>PID Controller and its Problem</h1>
<section id="mathematical-formulation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h2>
<p>A PID controller is a feedback control loop that continuously calculates an “error” value <span class="math inline">\(e(t)\)</span> as the difference between a desired setpoint <span class="math inline">\(r(t)\)</span> and a measured process variable <span class="math inline">\(y(t)\)</span>:</p>
<p><span class="math display">\[e(t) = r(t) - y(t)\]</span></p>
<p>Based on this error, the PID controller generates a control output <span class="math inline">\(u(t)\)</span> by combining three distinct terms:</p>
<ul>
<li><strong>Proportional Term (<span class="math inline">\(P\)</span>-term):</strong> Accounts for the <em>current</em> error.</li>
<li><strong>Integral Term (<span class="math inline">\(I\)</span>-term):</strong> Accounts for the <em>accumulation</em> of past errors.</li>
<li><strong>Derivative Term (<span class="math inline">\(D\)</span>-term):</strong> Accounts for the <em>rate of change</em> of the error.</li>
</ul>
<p>Combining these, the <strong>continuous-time PID control law</strong> is given by:</p>
<p><span class="math display">\[u(t) = K_p e(t) + K_i \int e(t) dt + K_d \frac{de(t)}{dt}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(u(t)\)</span> is the controller’s output.</li>
<li><span class="math inline">\(e(t)\)</span> is the error at time <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(K_p\)</span> is the proportional gain.</li>
<li><span class="math inline">\(K_i\)</span> is the integral gain.</li>
<li><span class="math inline">\(K_d\)</span> is the derivative gain.</li>
</ul>
</section>
<section id="but-why-p-i-and-d-why-not-just-use-the-current-error" class="level2">
<h2 class="anchored" data-anchor-id="but-why-p-i-and-d-why-not-just-use-the-current-error">But Why P, I, and D? Why not just use the current error?</h2>
<section id="the-proportional-p-term-present" class="level3">
<h3 class="anchored" data-anchor-id="the-proportional-p-term-present">The Proportional (P) Term: Present</h3>
<p><span class="math display">\[u_P(t) = K_p e(t)\]</span></p>
<ul>
<li><p><strong>Present:</strong> If the error is large, the controller acts strongly; if the error is small, it acts weakly. =&gt; quickly drive the system towards the setpoint.</p></li>
<li><p><strong>Gradual Loss Problem</strong>: There are some system where the output just naturally decays over time (like heat loss from a room, or friction in a motor). A simplified model could be, notice that for the output <span class="math inline">\(y\)</span> to be maintained at a constant setpoint <span class="math inline">\(r\)</span> (i.e., <span class="math inline">\(\frac{dy}{dt}=0\)</span>), the control input <span class="math inline">\(u\)</span> must provide a continuous effort to compensate: <span class="math inline">\(u_{required} = \frac{ay}{b}\)</span>. <strong>This system is the core problem</strong>:</p>
<p><span class="math display">\[\frac{dy}{dt} = -ay + bu\]</span></p>
<p>So what we require is that for this type of model to be at steady state, <span class="math inline">\(\frac{dy}{dt}=0 \implies ay_{ss} = bu_{ss}\)</span>.</p>
<p><strong>But the problem is here!!!</strong> With P-control, we can only have <span class="math inline">\(u_{ss} = K_p (r - y_{ss})\)</span> that kinda only acts based on the last timestep error. <span class="math display">\[ay_{ss} = bK_p (r - y_{ss})\]</span> <span class="math display">\[ay_{ss} = bK_pr - bK_py_{ss}\]</span> <span class="math display">\[y_{ss} = \frac{K_p r}{(K_p + a/b)}\]</span></p>
<p>Since <span class="math inline">\(a,b,K_p\)</span> are positive, <span class="math inline">\(y_{ss}\)</span> will always be less than <span class="math inline">\(r\)</span>, meaning there will always be a <strong>non-zero steady-state error</strong>: <span class="math inline">\(e_{ss} = r - y_{ss} \ne 0\)</span>.</p>
<p><strong>Therefore</strong> In this time of time-decaying systems, a sole P-Term simply cannot provide a sustained, non-zero output, simply because it <strong>only acts with the current error, and never act for the upcoming decay</strong></p></li>
</ul>
</section>
<section id="the-integral-i-term-gradual-push-effort" class="level3">
<h3 class="anchored" data-anchor-id="the-integral-i-term-gradual-push-effort">The Integral (I) Term: Gradual Push Effort</h3>
<p><span class="math display">\[u_I(t) = K_i \int e(t) dt\]</span></p>
<ul>
<li><strong>Compensate the gradual Loss:</strong> Probably now you know what to do… we <strong>push a little more</strong>, in such <strong>time-decaying system, we need continuous effort</strong> to to maintain the setpoint. It does this by continuously accumulating errors over time.</li>
<li><strong>Analogy:</strong> You’re driving at 99 km/h when the limit is 100 km/h (small error). The P-term might give only a tiny gas pedal press. But you know, car on the street is exactly this type of <strong>time-decaying system</strong> (<span class="math inline">\(\frac{dy}{dt} = -ay + bu\)</span>) =&gt; To maintain 99 km/h for a long time, the I-term “notices” this persistent deficit and <em>gradually</em> pushes the gas pedal a little harder and holds it there until you finally reach 100 km/h.</li>
<li><strong>Drawback:</strong> The integral term can make the system slower to respond and potentially cause overshoot or oscillations if its gain <span class="math inline">\(K_i\)</span> is set too high, because it’s reacting to <em>past</em> errors, not current or future ones.</li>
<li><strong>When does this accumulated stop?</strong> I would say almost never, because we have a time-decaying system, so we always need it.</li>
<li><strong>BUT</strong>, of course sometimes we want do stop overshooting it, therefore we have another term down here…</li>
</ul>
</section>
<section id="the-derivative-d-term-anticipation-and-damping" class="level3">
<h3 class="anchored" data-anchor-id="the-derivative-d-term-anticipation-and-damping">The Derivative (D) Term: Anticipation and Damping</h3>
<p><span class="math display">\[u_D(t) = K_d \frac{de(t)}{dt}\]</span></p>
<ul>
<li><strong>Anticipation and Damping :</strong>This is really nice.
<ul>
<li>If the error is <strong>rapidly increasing</strong> (either negative or positive quantitatively), the D-term will counteract it quickly.</li>
<li>If the error is <strong>rapidly decreasing</strong> (meaning the system is approaching the setpoint quickly), the D-term will reduce the control action to prevent overshoot.</li>
</ul></li>
<li><strong>Analogy:</strong> You see a sharp turn (error changing rapidly) approaching in your car. You start braking <em>before</em> the turn to slow down smoothly and avoid overshooting the curve. Or, you’re speeding towards the 100 km/h limit; as you get closer, the D-term will gradually ease off the gas, preventing you from overshooting.</li>
<li><strong>Benefits:</strong> Reduces overshoot, reduces oscillations, and improves the transient response (how quickly and smoothly the system reaches the setpoint).</li>
<li><strong>Drawback:</strong> The D-term is very sensitive to noise in the measurement signal. Rapid changes in noisy signals can lead to large, jerky control actions.</li>
</ul>
</section>
</section>
</section>
<section id="the-lti-system-dynamics-the-state-space-model" class="level1">
<h1>The LTI System Dynamics: The State-Space Model</h1>
<p>Specifically in <strong>Linear Time-Invariant (LTI) systems</strong>, the differential equation <span class="math inline">\(\dot{\mathbf{x}}(t)=\mathbf{A}\mathbf{x}(t)+\mathbf{B}\mathbf{u}(t)\)</span> is known as the <strong>state-space representation</strong> of a dynamic system. <span class="math inline">\(\mathbf{x}(t)\)</span> contains the <strong>state variables</strong> of the system.</p>
<p><strong>It can always be First-Order Form like this!!!:</strong> Even if a physical system is described by a single high-order differential equation (e.g., a second-order equation for a mass-spring-damper) as example below, it can <em>always</em> be converted into a set of coupled <strong>first-order differential equations</strong>, will be described in the below example. Each row of the state-space equation represents the time derivative of one of other state variables.</p>
<p><strong>What about nonlinear or time-varying systems?</strong> For these systems, we can <strong>linearize it</strong> by approximating around a specific operating point. This linear approximation is valid only close to that operating point. THen apply LQR and MPC as normal.</p>
<section id="example-lti-system-the-mass-spring-damper" class="level2">
<h2 class="anchored" data-anchor-id="example-lti-system-the-mass-spring-damper">Example LTI System: The Mass-Spring-Damper</h2>
<p><strong>System Description:</strong> This is a common <strong>second-order system</strong>. Consider a mass <span class="math inline">\(m\)</span> (kg) connected to a spring with stiffness <span class="math inline">\(k\)</span> (N/m) and a damper with damping coefficient <span class="math inline">\(b\)</span> (Ns/m). An external force <span class="math inline">\(F(t)\)</span> (N) is applied to the mass, causing a displacement <span class="math inline">\(y(t)\)</span> (m) from its equilibrium position.</p>
<p><strong>1. Governing Differential Equation:</strong> Applying Newton’s Second Law (<span class="math inline">\(\sum F = m \ddot{y}\)</span>) to the mass:</p>
<ul>
<li>Applied force: <span class="math inline">\(+F(t)\)</span></li>
<li>Spring force (restoring): <span class="math inline">\(-k y(t)\)</span></li>
<li>Damping force (opposing velocity): <span class="math inline">\(-b \dot{y}(t)\)</span></li>
</ul>
<p>So, we have now a <strong>second-order</strong> linear ordinary differential equation: <span class="math display">\[m\ddot{y}(t) + b\dot{y}(t) + k y(t) = F(t)\]</span> <span class="math display">\[m\ddot{y}(t) = F(t) - b\dot{y}(t) - k y(t)\]</span></p>
<p><strong>2. Converting to State-Space Form:</strong> To convert this second-order equation into the <strong>first-order</strong> state-space form, we define state variables. A common choice is to pick the position and velocity as states:</p>
<ul>
<li><span class="math inline">\(x_1(t) = y(t)\)</span> (the position of the mass)</li>
<li><span class="math inline">\(x_2(t) = \dot{y}(t)\)</span> (the velocity of the mass)</li>
</ul>
<p>Now, we need to express the derivatives of these state variables in terms of the states themselves and the input <span class="math inline">\(F(t)\)</span>. <span class="math display">\[\dot{x_1}(t) = \dot{y}(t) = x_2(t)\]</span> <span class="math display">\[\ddot{y}(t) = \frac{1}{m} F(t) - \frac{b}{m}\dot{y}(t) - \frac{k}{m}y(t)\]</span> Substituting our state variables (<span class="math inline">\(y(t)=x_1(t)\)</span> and <span class="math inline">\(\dot{y}(t)=x_2(t)\)</span>) and our input <span class="math inline">\(u(t) = F(t)\)</span>: <span class="math display">\[\dot{x_2}(t) = -\frac{k}{m}x_1(t) - \frac{b}{m}x_2(t) + \frac{1}{m}u(t)\]</span></p>
<p><strong>3. Writing in Matrix Form:</strong> Now, we can assemble these first-order equations into the state-space matrix form <span class="math inline">\(\dot{\mathbf{x}}(t)=\mathbf{A}\mathbf{x}(t)+\mathbf{B}\mathbf{u}(t)\)</span>:</p>
<p><span class="math display">\[\begin{pmatrix} \dot{x_1}(t) \\ \dot{x_2}(t) \end{pmatrix} = \begin{pmatrix} 0 &amp; 1 \\ -\frac{k}{m} &amp; -\frac{b}{m} \end{pmatrix} \begin{pmatrix} x_1(t) \\ x_2(t) \end{pmatrix} + \begin{pmatrix} 0 \\ \frac{1}{m} \end{pmatrix} u(t)\]</span></p>
<p>From this, we can identify the statematrix <span class="math inline">\(\mathbf{A}\)</span> and input matrix <span class="math inline">\(\mathbf{B}\)</span>: <span class="math display">\[\mathbf{A} = \begin{pmatrix} 0 &amp; 1 \\ -\frac{k}{m} &amp; -\frac{b}{m} \end{pmatrix}, \mathbf{B} = \begin{pmatrix} 0 \\ \frac{1}{m} \end{pmatrix}\]</span></p>
</section>
</section>
<section id="the-linear-quadratic-regulator-lqr---model-hint-to-optimal-control" class="level1">
<h1>The Linear Quadratic Regulator (LQR) - Model-hint to Optimal Control</h1>
<p>PID relies on heuristic tuning and does not handle multi-variable systems. This is where the <strong>Linear Quadratic Regulator (LQR)</strong> steps in. It operates on any system platform that follow this <strong>linear time-invariant (LTI) state-space model</strong>: <span class="math display">\[\dot{\mathbf{x}}(t) = \mathbf{A}\mathbf{x}(t) + \mathbf{B}\mathbf{u}(t)\]</span></p>
<p>This model is a linear approximation of a real system, assumed to be valid around an operating point (e.g., linearization around an equilibrium).</p>
<section id="formulate-into-integral-of-terms-using-x-and-u" class="level2">
<h2 class="anchored" data-anchor-id="formulate-into-integral-of-terms-using-x-and-u">Formulate into integral of terms using x and u</h2>
<p>The formal LQR problem is to find the optimal control input <span class="math inline">\(\mathbf{u}^*(t)\)</span> that minimizes the cost function <span class="math inline">\(J\)</span>, subject to the system dynamics:</p>
<p><span class="math display">\[\text{Minimize } J = \int_0^\infty (\mathbf{x}^T(t)\mathbf{Q}\mathbf{x}(t) + \mathbf{u}^T(t)\mathbf{R}\mathbf{u}(t)) dt\]</span> <span class="math display">\[\text{Subject to: } \dot{\mathbf{x}}(t) = \mathbf{A}\mathbf{x}(t) + \mathbf{B}\mathbf{u}(t)\]</span></p>
<p>Our goal is now, choosing the weighting matrices <span class="math inline">\(\mathbf{Q}\)</span> and <span class="math inline">\(\mathbf{R}\)</span>, we can tune the controller to prioritize different aspects of performance:</p>
<ul>
<li><strong>Larger <span class="math inline">\(\mathbf{Q}\)</span>:</strong> driving states to zero quickly</li>
<li><strong>Larger <span class="math inline">\(\mathbf{R}\)</span>:</strong> minimizing control effort</li>
</ul>
<p>You know what? LQR is a linear state-feedback control system, so it people from long time ago has found out it also satisfies this form:</p>
<p><span class="math display">\[\mathbf{u}(t) = -\mathbf{K}\mathbf{x}(t)\]</span></p>
<p>well, we do not know what <span class="math inline">\(K\)</span> is, we need to find <span class="math inline">\(P\)</span> to calculate <span class="math inline">\(K\)</span>:</p>
<p><span class="math display">\[\mathbf{K} = \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\]</span></p>
<p>But <span class="math inline">\(\mathbf{P} \in \mathbb{R}^{n \times n}\)</span> is also sth that we need to find.</p>
<p>People long time ago just started by adding and subtracting <span class="math inline">\(\mathbf{x}_0^T\mathbf{P}\mathbf{x}_0\)</span> from <span class="math inline">\(J\)</span> to see what they can explore from here:</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 - \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty (\mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{u}^T\mathbf{R}\mathbf{u}) dt\]</span></p>
<p>Substituting the integral form of <span class="math inline">\(-\mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 = \int_0^\infty ( \frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}))dt\)</span>:</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty \left( \frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}) + \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{u}^T\mathbf{R}\mathbf{u} \right) dt\]</span></p>
<p>Now we derive <span class="math inline">\(\frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x})\)</span>. Since <span class="math inline">\(\mathbf{P}\)</span> is a constant, symmetric matrix (<span class="math inline">\(\mathbf{P} = \mathbf{P}^T\)</span>):</p>
<p><span class="math display">\[\frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}) = \dot{\mathbf{x}}^T\mathbf{P}\mathbf{x} + \mathbf{x}^T\mathbf{P}\dot{\mathbf{x}}\]</span></p>
<p>Now, substitute <span class="math inline">\(\dot{\mathbf{x}} = \mathbf{A}\mathbf{x} + \mathbf{B}\mathbf{u}\)</span> into this expression:</p>
<p><span class="math display">\[\frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}) = (\mathbf{A}\mathbf{x} + \mathbf{B}\mathbf{u})^T\mathbf{P}\mathbf{x} + \mathbf{x}^T\mathbf{P}(\mathbf{A}\mathbf{x} + \mathbf{B}\mathbf{u})\]</span> <span class="math display">\[\frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}) = (\mathbf{x}^T\mathbf{A}^T + \mathbf{u}^T\mathbf{B}^T)\mathbf{P}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{A}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u}\]</span> <span class="math display">\[\frac{d}{dt}(\mathbf{x}^T\mathbf{P}\mathbf{x}) = \mathbf{x}^T\mathbf{A}^T\mathbf{P}\mathbf{x} + \mathbf{u}^T\mathbf{B}^T\mathbf{P}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{A}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u}\]</span></p>
<p>Substitute this back into the expression for <span class="math inline">\(J\)</span>:</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty \left( \mathbf{x}^T\mathbf{A}^T\mathbf{P}\mathbf{x} + \mathbf{u}^T\mathbf{B}^T\mathbf{P}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{A}\mathbf{x} + \mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u} + \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{u}^T\mathbf{R}\mathbf{u} \right) dt\]</span></p>
<p>Now, let’s group the terms. We can gather terms involving <span class="math inline">\(\mathbf{x}^T (\cdot) \mathbf{x}\)</span> and terms involving <span class="math inline">\(\mathbf{u}\)</span>. Note that <span class="math inline">\(\mathbf{u}^T\mathbf{B}^T\mathbf{P}\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u}\)</span> are scalars and transposes of each other (and since <span class="math inline">\(\mathbf{P}=\mathbf{P}^T\)</span>), they are equal. So their sum is <span class="math inline">\(2\mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u}\)</span>.</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty \left( \mathbf{x}^T(\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} + \mathbf{Q})\mathbf{x} + \mathbf{u}^T\mathbf{R}\mathbf{u} + 2\mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u} \right) dt\]</span></p>
<p>Now, we want to rewrite the terms dependent on <span class="math inline">\(\mathbf{u}\)</span> into a perfect square like:</p>
<p><span class="math display">\[(a + b)² = a² + 2ab + b²\]</span> <span class="math display">\[a² + 2ab = (a + b)² - b²\]</span></p>
<p>we somehow figuredout it looks like this, I also cannot derive it how, but thats the result:</p>
<p><span class="math display">\[\mathbf{u}^T\mathbf{R}\mathbf{u} + 2\mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{u} = (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x})^T \mathbf{R} (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x}) - \mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x}\]</span></p>
<p>Substitute this back into the expression for <span class="math inline">\(J\)</span>:</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty \left( \mathbf{x}^T(\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} + \mathbf{Q})\mathbf{x} + (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x})^T \mathbf{R} (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x}) - \mathbf{x}^T\mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x} \right) dt\]</span></p>
<section id="important-part" class="level3">
<h3 class="anchored" data-anchor-id="important-part">Important part</h3>
<p>Finally, group the <span class="math inline">\(\mathbf{x}^T(\cdot)\mathbf{x}\)</span> terms <strong>AGAIN, we did this twice aigoo</strong>:</p>
<p><span class="math display">\[J = \mathbf{x}_0^T\mathbf{P}\mathbf{x}_0 + \int_0^\infty \left( \mathbf{x}^T(\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} + \mathbf{Q} - \mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P})\mathbf{x} + (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x})^T \mathbf{R} (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x}) \right) dt\]</span></p>
<p>To minimize <span class="math inline">\(J\)</span>, we need to make the integral as small as possible. Let’s analyze the terms within the integral:</p>
<ol type="1">
<li>The term <span class="math inline">\(\mathbf{x}^T(\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} + \mathbf{Q} - \mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P})\mathbf{x}\)</span> depends only on the state <span class="math inline">\(\mathbf{x}\)</span>, which is a consequence of the control.</li>
<li>The term <span class="math inline">\((\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x})^T \mathbf{R} (\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x})\)</span> is a quadratic form involving <span class="math inline">\(\mathbf{u}\)</span>. Since <span class="math inline">\(\mathbf{R}\)</span> is a positive definite matrix, this term is always greater than or equal to zero.</li>
</ol>
<p>To minimize <span class="math inline">\(J\)</span>, we must choose <span class="math inline">\(\mathbf{u}\)</span> such that the second term in the integral is zero (its minimum possible value). This occurs when:</p>
<p><span class="math display">\[\mathbf{u} + \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x} = \mathbf{0}\]</span></p>
<p>Imagine we already have a <strong>optimal control</strong>: <span class="math display">\[\mathbf{u}^*(t) = -\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\mathbf{x}(t)\]</span></p>
<p>Imagine a specific case at a convergence, this <span class="math inline">\(\mathbf{u}^*(t)\)</span> term is only 0, only when <span class="math inline">\(\mathbf{x}\)</span> must also be zero. Therefore, interestingly:</p>
<p><span class="math display">\[\mathbf{A}^T\mathbf{P} + \mathbf{P}\mathbf{A} + \mathbf{Q} - \mathbf{P}\mathbf{B}\mathbf{R}^{-1}\mathbf{B}^T\mathbf{P} = \mathbf{0}\]</span></p>
<p>This is the famous <strong>Algebraic Riccati Equation (ARE)</strong> which we can solve numerically.</p>
<p><strong>FInally Back to the Top: Now Calculate <span class="math inline">\(\mathbf{K}\)</span></strong> using the obtained <span class="math inline">\(\mathbf{P}\)</span> to get optimal control <span class="math inline">\(\mathbf{u}(t)\)</span>:</p>
<p><span class="math display">\[\mathbf{K} = \mathbf{R}^{-1}\mathbf{B}^T\mathbf{P}\]</span> <span class="math display">\[\mathbf{u}(t) = -\mathbf{K}\mathbf{x}(t)\]</span></p>
<p>This means the controller takes the current state <span class="math inline">\(\mathbf{x}(t)\)</span>, multiplies it by the pre-computed gain matrix <span class="math inline">\(\mathbf{K}\)</span>, and applies this as the control input. The negative sign indicates feedback (driving the state towards zero).</p>
</section>
</section>
<section id="derivation-of-linear-optimal-control-u--kx-and-quadratic-value-function-vxxt-px" class="level2">
<h2 class="anchored" data-anchor-id="derivation-of-linear-optimal-control-u--kx-and-quadratic-value-function-vxxt-px">Derivation of Linear Optimal Control (<span class="math inline">\(u^* = -Kx\)</span>) and Quadratic Value Function (<span class="math inline">\(V(x)=x^T Px\)</span>)</h2>
<section id="bellman-optimality---the-value-function-cost-to-go" class="level3">
<h3 class="anchored" data-anchor-id="bellman-optimality---the-value-function-cost-to-go">Bellman Optimality -&gt; The Value Function (Cost-to-Go):</h3>
<p>if a path from point A to point C is optimal, then any segment of that path (e.g., from point B to point C, where B is on the path) must also be optimal from point B. This motivated the transformation of cost function J to the value function below.</p>
<p><strong>The Cost Function (J):</strong> Our problem statement is to find <span class="math inline">\(u(t)\)</span> that minimizes: <span class="math display">\[J = \int_{0}^{\infty} (x^T(\tau)Qx(\tau) + u^T(\tau)Ru(\tau))d\tau\]</span></p>
<p>This is the objective.</p>
<p><strong>The Value Function (V) is Defined in Terms of J:</strong> The value function V(x(t),t)$, as the minimum possible future cost from the current state <span class="math inline">\(x(t)\)</span> at time <span class="math inline">\(t\)</span> to the end of the control horizon (which is <span class="math inline">\(\infty\)</span> for infinite-horizon LQR). <span class="math display">\[V(x(t),t) = \min_{u(\tau),\tau \ge t} \int_{t}^{\infty} (x^T(\tau)Qx(\tau) + u^T(\tau)Ru(\tau))d\tau\]</span></p>
<p>So, <span class="math inline">\(V(x(t),t)\)</span> is literally the minimum value of a section of the integral <span class="math inline">\(J\)</span>.</p>
<p><strong>Time-Invariance of <span class="math inline">\(V(x)\)</span>:</strong> For an LTI system with an infinite horizon and constant cost weights, the optimal cost-to-go function <span class="math inline">\(V\)</span> will eventually reach a steady-state. This means it will no longer explicitly depend on time <span class="math inline">\(t\)</span>. Therefore, <span class="math inline">\(\frac{\partial V}{\partial t} = 0\)</span>. <span class="math display">\[-\frac{\partial V}{\partial t} = \min_{u} \left[ x^T Q x + u^T R u + \left(\frac{\partial V}{\partial x}\right)^T (Ax + Bu) \right]\]</span></p>
<p><span class="math display">\[0 = \min_{u} \left[ x^T Q x + u^T R u + \frac{\partial V}{\partial t} + \left(\frac{\partial V}{\partial x}\right)^T (Ax + Bu) \right]\]</span></p>
</section>
<section id="deriving-u--kx" class="level3">
<h3 class="anchored" data-anchor-id="deriving-u--kx">Deriving <span class="math inline">\(u^* = -Kx\)</span></h3>
<p>Let’s focus on the term inside the <span class="math inline">\(\min_{u}\)</span> operator. This is a function of <span class="math inline">\(u\)</span>. To find the <span class="math inline">\(u\)</span> that minimizes it, we take the partial derivative with respect to <span class="math inline">\(u\)</span> and set it to zero.</p>
<p>Let <span class="math inline">\(g(u) = x^T Q x + u^T R u + \left(\frac{\partial V}{\partial x}\right)^T (Ax + Bu)\)</span>. We’re minimizing <span class="math inline">\(g(u)\)</span> with respect to <span class="math inline">\(u\)</span>. Only terms involving <span class="math inline">\(u\)</span> are relevant:</p>
<p><span class="math display">\[g(u) = u^T R u + \left(\frac{\partial V}{\partial x}\right)^T Bu\]</span></p>
<p>Taking the derivative with respect to <span class="math inline">\(u\)</span>:</p>
<p><span class="math display">\[\frac{\partial g}{\partial u} = 2Ru + B^T \frac{\partial V}{\partial x}\]</span></p>
<p>Set to zero to find the optimal <span class="math inline">\(u^*\)</span>:</p>
<p><span class="math display">\[2Ru^* + B^T \frac{\partial V}{\partial x} = 0\]</span> <span class="math display">\[u^* = -\frac{1}{2} R^{-1} B^T \frac{\partial V}{\partial x}\]</span></p>
<p>This is the crucial step: The optimal control is found to be a linear function of the gradient of the value function!</p>
</section>
<section id="deriving-vxxt-px" class="level3">
<h3 class="anchored" data-anchor-id="deriving-vxxt-px">Deriving <span class="math inline">\(V(x)=x^T Px\)</span></h3>
<p>At this point, we have <span class="math inline">\(u^*\)</span> expressed in terms of <span class="math inline">\(\frac{\partial V}{\partial x}\)</span>. Now we need to solve for <span class="math inline">\(V(x)\)</span>. This is where the specific structure of the LQR problem (linear dynamics, quadratic cost) becomes paramount.</p>
<p>Since the problem is Linear-Quadratic, it is a known property from optimal control theory that the optimal value function <span class="math inline">\(V(x)\)</span> will be a quadratic form of the state. This is not just a guess, but a deduction based on the inherent structure of LQ problems.</p>
<ul>
<li><strong>Why Quadratic?</strong> If <span class="math inline">\(V(x)\)</span> were linear, its second derivative would be zero, which wouldn’t match the quadratic terms in the HJB. If it were higher order, the derivatives would lead to more complex non-linear equations, which would contradict the simplicity and linearity that arise from the problem. The quadratic form <span class="math inline">\(x^T Px\)</span> is the lowest-order non-trivial form that is consistent with the problem’s structure.</li>
<li><strong>Symmetry:</strong> <span class="math inline">\(P\)</span> is typically chosen to be symmetric (<span class="math inline">\(P=P^T\)</span>) because <span class="math inline">\(x^T Px = x^T P^T x\)</span>. Any asymmetric part of <span class="math inline">\(P\)</span> cancels out in the quadratic form, so we enforce symmetry for uniqueness and consistency.</li>
</ul>
<p>So, we propose (or infer) the form:</p>
<p><span class="math display">\[V(x) = x^T Px\]</span></p>
<p>where <span class="math inline">\(P\)</span> is a symmetric positive definite matrix.</p>
<p>Now, calculate the gradient of <span class="math inline">\(V(x)\)</span> with respect to <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[\frac{\partial V}{\partial x} = 2Px\]</span></p>
</section>
<section id="deriving-are" class="level3">
<h3 class="anchored" data-anchor-id="deriving-are">Deriving ARE</h3>
<p>Substitute <span class="math inline">\(\frac{\partial V}{\partial x} = 2Px\)</span> back into the expression for <span class="math inline">\(u^*\)</span>:</p>
<p><span class="math display">\[u^* = -\frac{1}{2} R^{-1} B^T (2Px)\]</span> <span class="math display">\[u^* = -R^{-1} B^T Px\]</span></p>
<p>This is our desired linear state feedback law! Here, <span class="math inline">\(K = R^{-1} B^T P\)</span>.</p>
<p>Now, substitute <span class="math inline">\(u^*\)</span> and <span class="math inline">\(\frac{\partial V}{\partial x}\)</span> back into the simplified HJB equation:</p>
<p><span class="math display">\[0 = x^T Q x + (-R^{-1} B^T Px)^T R (-R^{-1} B^T Px) + (2Px)^T (Ax + B(-R^{-1} B^T Px))\]</span> <span class="math display">\[0 = x^T Q x + x^T P^T (B^T)^T (R^{-1})^T R R^{-1} B^T Px + 2x^T P^T (Ax - BR^{-1} B^T Px)\]</span> Since <span class="math inline">\(P = P^T\)</span> and <span class="math inline">\(R\)</span> is symmetric (<span class="math inline">\(R=R^T\)</span>), <span class="math inline">\(R^{-1}\)</span> is also symmetric (<span class="math inline">\((R^{-1})^T = R^{-1}\)</span>). Also, <span class="math inline">\((B^T)^T = B\)</span>.</p>
<p><span class="math display">\[0 = x^T Q x + x^T P B R^{-1} B^T Px + 2x^T PAx - 2x^T P B R^{-1} B^T Px\]</span> <span class="math display">\[0 = x^T Q x + 2x^T PAx - x^T P B R^{-1} B^T Px\]</span></p>
<p>Recognizing that <span class="math inline">\(2x^T PAx = x^T PAx + x^T A^T P^T x = x^T (A^T P + PA)x\)</span> (since <span class="math inline">\(P\)</span> is symmetric):</p>
<p><span class="math display">\[0 = x^T (Q + A^T P + PA - P B R^{-1} B^T P)x\]</span></p>
<p>For this equation to hold for any state <span class="math inline">\(x\)</span>, the matrix in the parenthesis must be identically zero.</p>
<p><span class="math display">\[A^T P + PA - P B R^{-1} B^T P + Q = 0\]</span></p>
<p>This is the <strong>Algebraic Riccati Equation (ARE)</strong>.</p>
</section>
</section>
</section>
<section id="mpc" class="level1">
<h1>MPC</h1>
<section id="transformation-to-a-standard-quadratic-program-qp" class="level2">
<h2 class="anchored" data-anchor-id="transformation-to-a-standard-quadratic-program-qp">Transformation to a Standard Quadratic Program (QP)</h2>
<p>The goal is to eliminate the state variables <span class="math inline">\(x(k+i|k)\)</span> from the optimization problem, leaving only the control input sequence <span class="math inline">\(U_k\)</span> as the decision variables. This is possible because the state evolution is precisely defined by the linear system dynamics, which act as equality constraints.</p>
<section id="prediction-of-future-states" class="level3">
<h3 class="anchored" data-anchor-id="prediction-of-future-states">1. Prediction of Future States:</h3>
<p>We start by recursively expanding the system dynamics equation: <span class="math inline">\(x(k+i+1|k) = Ax(k+i|k) + Bu(k+i|k)\)</span>.</p>
<ul>
<li><strong>Initial State:</strong> <span class="math inline">\(x(k|k) = x(k)\)</span> (the current measured state).</li>
<li><strong>1-step ahead prediction:</strong> <span class="math inline">\(x(k+1|k) = Ax(k|k) + Bu(k|k)\)</span></li>
<li><strong>2-step ahead prediction:</strong> <span class="math inline">\(x(k+2|k) = Ax(k+1|k) + Bu(k+1|k)\)</span> Substitute <span class="math inline">\(x(k+1|k)\)</span>: <span class="math inline">\(x(k+2|k) = A(Ax(k|k) + Bu(k|k)) + Bu(k+1|k)\)</span> <span class="math inline">\(x(k+2|k) = A^2 x(k|k) + ABu(k|k) + Bu(k+1|k)\)</span></li>
</ul>
<p>And so on, up to <span class="math inline">\(H_p\)</span> steps:</p>
<p>Generalizing, the predicted state at any future time <span class="math inline">\(k+i\)</span> can be expressed as a sum of terms related to the initial state <span class="math inline">\(x(k)\)</span> and the future control inputs <span class="math inline">\(u(k|k), \dots, u(k+i-1|k)\)</span>:</p>
<p><span class="math display">\[x(k+i|k) = A^i x(k) + \sum_{j=0}^{i-1} A^{i-1-j} Bu(k+j|k)\]</span></p>
<p>Now, let’s stack all the predicted states and controls into large vectors.</p>
<p>Let <span class="math inline">\(X_k = \begin{bmatrix} x(k+1|k) \\ x(k+2|k) \\ \vdots \\ x(k+H_p|k) \end{bmatrix}\)</span> and <span class="math inline">\(U_k = \begin{bmatrix} u(k|k) \\ u(k+1|k) \\ \vdots \\ u(k+H_c-1|k) \end{bmatrix}\)</span> (remembering the assumption that <span class="math inline">\(u\)</span> is constant after <span class="math inline">\(H_c-1\)</span>).</p>
<p>We can write the entire sequence of future states as:</p>
<p><span class="math display">\[X_k = \mathbf{\Phi} x(k) + \mathbf{\Gamma} U_k\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mathbf{\Phi}\)</span> is a large block matrix derived from powers of <span class="math inline">\(A\)</span>.</li>
<li><span class="math inline">\(\mathbf{\Gamma}\)</span> is a large block lower triangular matrix (often called the Toeplitz matrix or controllability matrix) containing terms like <span class="math inline">\(B, AB, A^2 B, \dots\)</span>. Its structure reflects how current and past controls affect future states.</li>
</ul>
</section>
<section id="substituting-into-the-objective-function" class="level3">
<h3 class="anchored" data-anchor-id="substituting-into-the-objective-function">2. Substituting into the Objective Function:</h3>
<p>Recall the objective function:</p>
<p><span class="math display">\[J(U_k, x(k)) = \sum_{i=0}^{H_p-1} \left( \|x(k+i|k) - x_{ref}(k+i)\|_Q^2 + \|u(k+i|k) - u_{ref}(k+i)\|_R^2 \right) + \|x(k+H_p|k) - x_{ref}(k+H_p)\|_P^2\]</span></p>
<p>We can rewrite this in a compact quadratic form. Let’s simplify by assuming <span class="math inline">\(x_{ref}=0\)</span> and <span class="math inline">\(u_{ref}=0\)</span> for now to highlight the structure. The general case simply introduces linear terms.</p>
<p><span class="math display">\[J(U_k, x(k)) = \sum_{i=0}^{H_p-1} x(k+i|k)^T Q x(k+i|k) + \sum_{i=0}^{H_c-1} u(k+i|k)^T R u(k+i|k) + x(k+H_p|k)^T P x(k+H_p|k)\]</span></p>
<p>By substituting <span class="math inline">\(x(k+i|k) = A^i x(k) + \sum_{j=0}^{i-1} A^{i-1-j} Bu(k+j|k)\)</span> into the expression for <span class="math inline">\(J\)</span>, the objective function becomes a quadratic function of <span class="math inline">\(U_k\)</span> and <span class="math inline">\(x(k)\)</span>:</p>
<p><span class="math display">\[J(U_k, x(k)) = \frac{1}{2} U_k^T H U_k + G^T U_k + J_{const}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(H\)</span> is a symmetric positive definite matrix (or positive semi-definite, depending on <span class="math inline">\(R\)</span>). It encapsulates the weights <span class="math inline">\(Q, R, P\)</span> and system matrices <span class="math inline">\(A, B\)</span>.</li>
<li><span class="math inline">\(G\)</span> is a vector that depends on the current state <span class="math inline">\(x(k)\)</span> and the reference trajectories.</li>
<li><span class="math inline">\(J_{const}\)</span> is a term that depends only on <span class="math inline">\(x(k)\)</span> and the reference trajectories, which doesn’t affect the minimization with respect to <span class="math inline">\(U_k\)</span>.</li>
</ul>
</section>
<section id="substituting-into-constraints" class="level3">
<h3 class="anchored" data-anchor-id="substituting-into-constraints">3. Substituting into Constraints:</h3>
<p>Similarly, all constraints (input, state, output) are originally expressed in terms of <span class="math inline">\(x(k+i|k)\)</span> and <span class="math inline">\(u(k+i|k)\)</span>. By substituting the state prediction equation <span class="math inline">\(x(k+i|k) = \mathbf{\Phi}_i x(k) + \mathbf{\Gamma}_i U_k\)</span> (where <span class="math inline">\(\mathbf{\Phi}_i\)</span> and <span class="math inline">\(\mathbf{\Gamma}_i\)</span> are parts of <span class="math inline">\(\mathbf{\Phi}\)</span> and <span class="math inline">\(\mathbf{\Gamma}\)</span> corresponding to time <span class="math inline">\(k+i\)</span>), all constraints can be rewritten purely in terms of <span class="math inline">\(x(k)\)</span> (which is known) and <span class="math inline">\(U_k\)</span> (the decision variables).</p>
<p>For example, a state constraint <span class="math inline">\(x_{min} \le x(k+i|k) \le x_{max}\)</span> becomes:</p>
<p><span class="math display">\[x_{min} \le \mathbf{\Phi}_{i} x(k) + \mathbf{\Gamma}_{i} \mathbf{U}_k \le x_{max}\]</span></p>
<p>This can be rearranged into the standard inequality form:</p>
<p><span class="math display">\[-\mathbf{\Gamma}_{i} \mathbf{U}_k \le \mathbf{\Phi}_{i} x(k) - x_{min}\]</span> <span class="math display">\[\mathbf{\Gamma}_{i} \mathbf{U}_k \le x_{max} - \mathbf{\Phi}_{i} x(k)\]</span></p>
<p>These are stacked for all <span class="math inline">\(i\)</span> and all types of constraints (input, state, output) into the compact form:</p>
<p><span class="math display">\[\mathbf{L} \mathbf{U}_k \le \mathbf{W}\]</span></p>
<p>where <span class="math inline">\(\mathbf{L}\)</span> and <span class="math inline">\(\mathbf{W}\)</span> are matrices and vectors that encapsulate all the constraint bounds, system matrices, and the current state <span class="math inline">\(x(k)\)</span>. Equality constraints (like the dynamics, if kept explicit rather than condensed) would form <span class="math inline">\(\mathbf{M}U_k = \mathbf{V}\)</span>.</p>
</section>
</section>
<section id="the-result-a-standard-qp-form" class="level2">
<h2 class="anchored" data-anchor-id="the-result-a-standard-qp-form">The Result: A Standard QP Form</h2>
<p>After this transformation, the MPC problem at each time step <span class="math inline">\(k\)</span> is reduced to:</p>
<p><strong>Minimize:</strong> <span class="math display">\[\frac{1}{2} U_k^T H U_k + G^T U_k\]</span> <strong>Subject to:</strong> <span class="math display">\[\mathbf{L}U_k \le \mathbf{W} \quad \text{(and possibly } \mathbf{M}U_k = \mathbf{V} \text{ for equality constraints)}\]</span></p>
<p>This is precisely the standard form of a Quadratic Program (QP), where <span class="math inline">\(U_k\)</span> is the optimization variable (what’s called ‘z’ in a generic QP solver). The matrices <span class="math inline">\(H, G, L, W, M, V\)</span> are updated at each time step based on the current measured state <span class="math inline">\(x(k)\)</span>.</p>
</section>
<section id="solutions-for-mpc-quadratic-programming-qp-solvers" class="level2">
<h2 class="anchored" data-anchor-id="solutions-for-mpc-quadratic-programming-qp-solvers">Solutions for MPC (Quadratic Programming (QP) Solvers)</h2>
<ul>
<li><strong>Active Set Methods:</strong> These methods work by iteratively selecting a subset of the inequality constraints to be “active” (i.e., treated as equality constraints). They solve an equality-constrained QP at each iteration, update the active set, and move towards the optimal solution.
<ul>
<li><strong>Pros:</strong> Highly reliable, provide exact solutions (within machine precision), often used for small to medium-sized problems.</li>
<li><strong>Cons:</strong> Can be slow for large problems, especially if many active set changes are required. Number of iterations can be high.</li>
</ul></li>
<li><strong>Interior-Point Methods:</strong> These methods transform the constrained QP into a sequence of unconstrained problems by adding “barrier functions” to the objective that penalize approaching the constraint boundaries. They then use Newton’s method to solve these unconstrained problems.
<ul>
<li><strong>Pros:</strong> Generally scale much better with problem size (fewer iterations, though each iteration is more complex) and are often faster for large-scale QPs. They work well with warm-starting (using the previous solution as an initial guess).</li>
<li><strong>Cons:</strong> Can be more complex to implement than active set methods.</li>
</ul></li>
<li><strong>Primal-Dual Methods:</strong> A broader class that includes many interior-point methods. They simultaneously solve the primal (original) QP problem and its dual problem.</li>
</ul>
</section>
<section id="derivation" class="level2">
<h2 class="anchored" data-anchor-id="derivation">Derivation</h2>
<section id="state-prediction-in-compact-matrix-form" class="level3">
<h3 class="anchored" data-anchor-id="state-prediction-in-compact-matrix-form">State Prediction in Compact Matrix Form</h3>
<p><strong>THE POINT: ONLY REPRESENT IN U, YOU CAN SEE IN THE MATRIX BELOW</strong></p>
<p><strong>Recap:</strong> We want to express all future predicted states <span class="math inline">\(x(k+i|k)\)</span> as a function of the current state <span class="math inline">\(x(k)\)</span> and the sequence of future control inputs <span class="math inline">\(U_k\)</span>.</p>
<p><strong>System:</strong> <span class="math inline">\(x(k+1)=Ax(k)+Bu(k)\)</span> <strong>Prediction Horizon:</strong> <span class="math inline">\(H_p\)</span> <strong>Control Horizon:</strong> <span class="math inline">\(H_c\)</span> (For simplicity, let’s assume <span class="math inline">\(H_c=H_p\)</span> for now. The case <span class="math inline">\(H_c&lt;H_p\)</span> just means some <span class="math inline">\(u\)</span>s are repeated, which is a minor modification.)</p>
<p><strong>Step-by-step prediction expansion:</strong></p>
<p><span class="math inline">\(x(k+1|k)=Ax(k)+Bu(k|k)\)</span> <span class="math inline">\(x(k+2|k)=Ax(k+1|k)+Bu(k+1|k)=A(Ax(k)+Bu(k|k))+Bu(k+1|k)=A^2x(k)+ABu(k|k)+Bu(k+1|k)\)</span> <span class="math inline">\(x(k+3|k)=Ax(k+2|k)+Bu(k+2|k)=A(A^2x(k)+ABu(k|k)+Bu(k+1|k))+Bu(k+2|k)=A^3x(k)+A^2Bu(k|k)+ABu(k+1|k)+Bu(k+2|k)\)</span> … and so on, up to <span class="math inline">\(x(k+H_p|k)\)</span>.</p>
<p><strong>Stacking the Predictions:</strong></p>
<p>Now, let’s define the stacked vectors:</p>
<ul>
<li><strong>Future States Vector:</strong> <span class="math inline">\(X_k = \begin{bmatrix} x(k+1|k) \\ x(k+2|k) \\ \vdots \\ x(k+H_p|k) \end{bmatrix}\)</span> (size <span class="math inline">\(n \cdot H_p \times 1\)</span>)</li>
<li><strong>Control Input Sequence (Decision Variable):</strong> <span class="math inline">\(U_k = \begin{bmatrix} u(k|k) \\ u(k+1|k) \\ \vdots \\ u(k+H_c-1|k) \end{bmatrix}\)</span> (size <span class="math inline">\(m \cdot H_c \times 1\)</span>)</li>
</ul>
<p>Substitute the expanded predictions into <span class="math inline">\(X_k\)</span>:</p>
<p><span class="math display">\[X_k = \begin{bmatrix} Ax(k)+Bu(k|k) \\ A^2x(k)+ABu(k|k)+Bu(k+1|k) \\ A^3x(k)+A^2Bu(k|k)+ABu(k+1|k)+Bu(k+2|k) \\ \vdots \\ A^{H_p}x(k)+A^{H_p-1}Bu(k|k)+\dots+Bu(k+H_p-1|k) \end{bmatrix}\]</span></p>
<p>Now, we separate the terms involving <span class="math inline">\(x(k)\)</span> from the terms involving <span class="math inline">\(U_k\)</span>:</p>
<p><span class="math display">\[X_k = \begin{bmatrix} A \\ A^2 \\ A^3 \\ \vdots \\ A^{H_p} \end{bmatrix} x(k) + \begin{bmatrix} B &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\ AB &amp; B &amp; 0 &amp; \dots &amp; 0 \\ A^2B &amp; AB &amp; B &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ A^{H_p-1}B &amp; A^{H_p-2}B &amp; A^{H_p-3}B &amp; \dots &amp; B \end{bmatrix} \begin{bmatrix} u(k|k) \\ u(k+1|k) \\ u(k+2|k) \\ \vdots \\ u(k+H_p-1|k) \end{bmatrix}\]</span></p>
<p>This is exactly the form: <span class="math inline">\(X_k = \mathbf{\Phi} x(k) + \mathbf{\Gamma} U_k\)</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{\Phi}\)</span> (State Contribution Matrix): <span class="math display">\[\mathbf{\Phi} = \begin{bmatrix} A \\ A^2 \\ \vdots \\ A^{H_p} \end{bmatrix}\]</span> <strong>Size:</strong> (<span class="math inline">\(n \cdot H_p\)</span>) <span class="math inline">\(\times n\)</span>. Each block is <span class="math inline">\(n \times n\)</span>. This matrix shows how the initial state <span class="math inline">\(x(k)\)</span> propagates to all future states if no control were applied.</li>
<li><span class="math inline">\(\mathbf{\Gamma}\)</span> (Control Contribution Matrix / Block Controllability Matrix): <span class="math display">\[\mathbf{\Gamma} = \begin{bmatrix} B &amp; 0 &amp; 0 &amp; \dots &amp; 0 \\ AB &amp; B &amp; 0 &amp; \dots &amp; 0 \\ A^2B &amp; AB &amp; B &amp; \dots &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ A^{H_p-1}B &amp; A^{H_p-2}B &amp; A^{H_p-3}B &amp; \dots &amp; B \end{bmatrix}\]</span> <strong>Size:</strong> (<span class="math inline">\(n \cdot H_p\)</span>) <span class="math inline">\(\times\)</span> (<span class="math inline">\(m \cdot H_p\)</span>). Each block is <span class="math inline">\(n \times m\)</span>. This lower triangular block matrix (sometimes called a block Toeplitz matrix) shows how the sequence of control inputs <span class="math inline">\(U_k\)</span> influences the future states. The “controllability” aspect comes from the powers of <span class="math inline">\(A\)</span> multiplying <span class="math inline">\(B\)</span>, indicating how inputs at different times propagate through the system.</li>
</ul>
<section id="numerical-example" class="level4">
<h4 class="anchored" data-anchor-id="numerical-example">Numerical Example</h4>
<p>Let’s use a very simple system: <span class="math inline">\(x(k+1)=Ax(k)+Bu(k)\)</span> <span class="math inline">\(A=\begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix}\)</span>, <span class="math inline">\(B=\begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</span> (This is a discrete-time integrator/position system) Let <span class="math inline">\(H_p=2\)</span> and <span class="math inline">\(H_c=2\)</span>.</p>
<p><strong>Predictions:</strong></p>
<p><span class="math inline">\(x(k+1|k)=Ax(k)+Bu(k|k)\)</span> <span class="math inline">\(x(k+2|k)=Ax(k+1|k)+Bu(k+1|k)=A^2x(k)+ABu(k|k)+Bu(k+1|k)\)</span></p>
<p><strong>Calculate powers of A and products with B:</strong> <span class="math inline">\(A^2 = \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix}\)</span> <span class="math inline">\(AB = \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</span></p>
<p><strong>Stacked Vectors:</strong> <span class="math inline">\(X_k = \begin{bmatrix} x(k+1|k) \\ x(k+2|k) \end{bmatrix}\)</span> <span class="math inline">\(U_k = \begin{bmatrix} u(k|k) \\ u(k+1|k) \end{bmatrix}\)</span></p>
<p><strong>Forming <span class="math inline">\(\mathbf{\Phi}\)</span> and <span class="math inline">\(\mathbf{\Gamma}\)</span>:</strong></p>
<p><span class="math display">\[X_k = \begin{bmatrix} A \\ A^2 \end{bmatrix} x(k) + \begin{bmatrix} B &amp; 0 \\ AB &amp; B \end{bmatrix} U_k\]</span></p>
<p>Substitute the numerical matrices:</p>
<p><span class="math display">\[\mathbf{\Phi} = \begin{bmatrix} \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} \\ \begin{bmatrix} 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix} \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix} \quad \text{(size } (2 \cdot 2) \times 2 = 4 \times 2 \text{)}\]</span></p>
<p><span class="math display">\[\mathbf{\Gamma} = \begin{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} &amp; \begin{bmatrix} 0 \\ 0 \end{bmatrix} \\ \begin{bmatrix} 0 \\ 1 \end{bmatrix} &amp; \begin{bmatrix} 0 \\ 1 \end{bmatrix} \end{bmatrix} = \begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} \quad \text{(size } (2 \cdot 2) \times (1 \cdot 2) = 4 \times 2 \text{)}\]</span></p>
<p>So, <span class="math inline">\(X_k = \mathbf{\Phi} x(k) + \mathbf{\Gamma} U_k\)</span> where all components are explicitly defined. This is how the state prediction is condensed.</p>
<hr>
</section>
</section>
<section id="substituting-into-the-objective-function-deriving-h-g-j_const" class="level3">
<h3 class="anchored" data-anchor-id="substituting-into-the-objective-function-deriving-h-g-j_const">Substituting into the Objective Function (Deriving H, G, J_const)</h3>
<p><strong>Recap:</strong> We want to transform <span class="math inline">\(J(U_k,x(k))\)</span> into <span class="math inline">\(\frac{1}{2}U_k^T H U_k + G^T U_k + J_{const}\)</span>.</p>
<p><strong>Objective Function:</strong></p>
<p><span class="math display">\[J(U_k,x(k)) = \sum_{i=0}^{H_p-1} (\|x(k+i|k)-x_{ref}(k+i)\|_Q^2 + \|u(k+i|k)-u_{ref}(k+i)\|_R^2) + \|x(k+H_p|k)-x_{ref}(k+H_p)\|_P^2\]</span></p>
<p>Let <span class="math inline">\(e_x(k+i|k)=x(k+i|k)-x_{ref}(k+i)\)</span> and <span class="math inline">\(e_u(k+i|k)=u(k+i|k)-u_{ref}(k+i)\)</span>. The term <span class="math inline">\(\|v\|_W^2 = v^T W v\)</span>.</p>
<p>Let’s adjust the sum for x states to start from <span class="math inline">\(i=1\)</span> to <span class="math inline">\(H_p\)</span> to align with the stacked <span class="math inline">\(X_k\)</span> derived in Part 1 (which starts from <span class="math inline">\(x(k+1|k)\)</span>). The terminal cost (with P) is explicitly included at <span class="math inline">\(H_p\)</span>.</p>
<p><span class="math display">\[J(U_k,x(k)) = \sum_{i=1}^{H_p} \|x(k+i|k)-x_{ref}(k+i)\|_Q^2 + \sum_{i=0}^{H_c-1} \|u(k+i|k)-u_{ref}(k+i)\|_R^2\]</span> <em>(Note: For clarity, the terminal cost is typically a separate term at <span class="math inline">\(x(k+H_p|k)\)</span> with weight <span class="math inline">\(P\)</span>. If <span class="math inline">\(P\)</span> is used as a <code>Q</code> for the last state in the sum, then <span class="math inline">\(Q_{H_p}\)</span> is <span class="math inline">\(P\)</span>. Let’s explicitly keep it in the sum by making <span class="math inline">\(Q_{H_p} = P\)</span> for <span class="math inline">\(i=H_p\)</span>.)</em></p>
<p>We can write the sums in stacked form:</p>
<p><span class="math display">\[J = E_X^T \bar{Q} E_X + E_U^T \bar{R} E_U\]</span></p>
<p>Where: * <span class="math inline">\(E_X = \begin{bmatrix} e_x(k+1|k) \\ e_x(k+2|k) \\ \vdots \\ e_x(k+H_p|k) \end{bmatrix}\)</span> (size <span class="math inline">\(n \cdot H_p \times 1\)</span>) * <span class="math inline">\(E_U = \begin{bmatrix} e_u(k|k) \\ e_u(k+1|k) \\ \vdots \\ e_u(k+H_c-1|k) \end{bmatrix}\)</span> (size <span class="math inline">\(m \cdot H_c \times 1\)</span>)</p>
<ul>
<li><span class="math inline">\(\bar{Q} = \text{diag}(Q, Q, \dots, Q, P)\)</span> (a block diagonal matrix of size <span class="math inline">\((n \cdot H_p) \times (n \cdot H_p)\)</span>, where the last block is <span class="math inline">\(P\)</span> for <span class="math inline">\(x(k+H_p|k)\)</span> and others are <span class="math inline">\(Q\)</span>).</li>
<li><span class="math inline">\(\bar{R} = \text{diag}(R, R, \dots, R)\)</span> (<span class="math inline">\(H_c\)</span> times, block diagonal matrix, size <span class="math inline">\((m \cdot H_c) \times (m \cdot H_c)\)</span>).</li>
</ul>
<p>Now, substitute <span class="math inline">\(X_k=\mathbf{\Phi}x(k)+\mathbf{\Gamma}U_k\)</span> into the objective. Let’s define the full reference vector <span class="math inline">\(X_{ref}=[x_{ref}(k+1)^T \dots x_{ref}(k+H_p)^T]^T\)</span> and <span class="math inline">\(U_{ref}=[u_{ref}(k)^T \dots u_{ref}(k+H_c-1)^T]^T\)</span>.</p>
<p>The stacked state error is <span class="math inline">\(E_X = X_k - X_{ref} = (\mathbf{\Phi}x(k)+\mathbf{\Gamma}U_k) - X_{ref}\)</span>. The stacked input error is <span class="math inline">\(E_U = U_k - U_{ref}\)</span>.</p>
<p>Then:</p>
<p><span class="math display">\[J = (\mathbf{\Phi}x(k)+\mathbf{\Gamma}U_k - X_{ref})^T \bar{Q} (\mathbf{\Phi}x(k)+\mathbf{\Gamma}U_k - X_{ref}) + (U_k - U_{ref})^T \bar{R} (U_k - U_{ref})\]</span></p>
<p>Now, expand and collect terms by powers of <span class="math inline">\(U_k\)</span>:</p>
<ul>
<li><p><strong>Quadratic term in <span class="math inline">\(U_k\)</span> (for <span class="math inline">\(H\)</span>):</strong> From the first term: <span class="math inline">\((\mathbf{\Gamma}U_k)^T \bar{Q} (\mathbf{\Gamma}U_k) = U_k^T \mathbf{\Gamma}^T \bar{Q} \mathbf{\Gamma} U_k\)</span> From the second term: <span class="math inline">\(U_k^T \bar{R} U_k\)</span> So, the full quadratic term is <span class="math inline">\(U_k^T (\mathbf{\Gamma}^T \bar{Q} \mathbf{\Gamma} + \bar{R}) U_k\)</span>. Therefore, <span class="math inline">\(H = 2(\mathbf{\Gamma}^T \bar{Q} \mathbf{\Gamma} + \bar{R})\)</span>. (The factor of 2 comes from the standard <span class="math inline">\(\frac{1}{2}z^T H z\)</span> form of QP objective).</p></li>
<li><p><strong>Linear term in <span class="math inline">\(U_k\)</span> (for <span class="math inline">\(G\)</span>):</strong> Let <span class="math inline">\(c_x = \mathbf{\Phi}x(k) - X_{ref}\)</span>. From the first term (cross-term <span class="math inline">\(2 c_x^T \bar{Q} \mathbf{\Gamma} U_k\)</span>): <span class="math inline">\(2(\mathbf{\Phi}x(k) - X_{ref})^T \bar{Q} \mathbf{\Gamma} U_k\)</span> From the second term (cross-term <span class="math inline">\(-2 U_{ref}^T \bar{R} U_k\)</span>): <span class="math inline">\(-2U_{ref}^T \bar{R} U_k\)</span> So, the full linear term is <span class="math inline">\(2(\mathbf{\Phi}x(k) - X_{ref})^T \bar{Q} \mathbf{\Gamma} U_k - 2U_{ref}^T \bar{R} U_k\)</span>. Therefore, <span class="math inline">\(G^T = 2(\mathbf{\Phi}x(k) - X_{ref})^T \bar{Q} \mathbf{\Gamma} - 2U_{ref}^T \bar{R}\)</span>. Or, <span class="math inline">\(G = 2\mathbf{\Gamma}^T \bar{Q} (\mathbf{\Phi}x(k) - X_{ref}) - 2\bar{R}^T U_{ref}\)</span>. Note that <span class="math inline">\(\bar{R}\)</span> is symmetric, so <span class="math inline">\(\bar{R}^T=\bar{R}\)</span>.</p></li>
<li><p><strong>Constant term (for <span class="math inline">\(J_{const}\)</span>):</strong> This term does not depend on <span class="math inline">\(U_k\)</span> and is effectively ignored by the optimizer. It includes: <span class="math inline">\((\mathbf{\Phi}x(k) - X_{ref})^T \bar{Q} (\mathbf{\Phi}x(k) - X_{ref}) + U_{ref}^T \bar{R} U_{ref}\)</span>. This term is important if you want to know the actual minimum cost, but not for finding the optimal <span class="math inline">\(U_k\)</span>.</p></li>
</ul>
<section id="numerical-example-1" class="level4">
<h4 class="anchored" data-anchor-id="numerical-example-1">Numerical Example</h4>
<p>Continue with our previous example: <span class="math inline">\(A=\begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \end{bmatrix}\)</span>, <span class="math inline">\(B=\begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</span> <span class="math inline">\(H_p=2\)</span>, <span class="math inline">\(H_c=2\)</span>. Let <span class="math inline">\(Q=\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\)</span> (identity matrix for state penalty), <span class="math inline">\(R=[0.1]\)</span> (scalar for input penalty). Let <span class="math inline">\(P=Q\)</span> (for simplicity of <span class="math inline">\(\bar{Q}\)</span> structure), <span class="math inline">\(x_{ref}=0\)</span>, <span class="math inline">\(u_{ref}=0\)</span>.</p>
<p>From Part 1: <span class="math inline">\(\mathbf{\Phi}=\begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix}\)</span> <span class="math inline">\(\mathbf{\Gamma}=\begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 0 \\ 1 &amp; 1 \end{bmatrix}\)</span></p>
<p>Also: <span class="math inline">\(\bar{Q}=\begin{bmatrix} Q &amp; 0 \\ 0 &amp; P \end{bmatrix} = \begin{bmatrix} \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} &amp; \begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} \\ \begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} &amp; \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix} \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}\)</span> (size <span class="math inline">\(4 \times 4\)</span>) <span class="math inline">\(\bar{R}=\begin{bmatrix} R &amp; 0 \\ 0 &amp; R \end{bmatrix}=\begin{bmatrix} 0.1 &amp; 0 \\ 0 &amp; 0.1 \end{bmatrix}\)</span> (size <span class="math inline">\(2 \times 2\)</span>)</p>
<p>Now, let’s compute <span class="math inline">\(H\)</span> (assuming <span class="math inline">\(H = 2(\mathbf{\Gamma}^T \bar{Q} \mathbf{\Gamma} + \bar{R})\)</span> as per the QP formulation): First, <span class="math inline">\(\mathbf{\Gamma}^T \bar{Q}\)</span>: <span class="math display">\[\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}\]</span> Then, <span class="math inline">\((\mathbf{\Gamma}^T \bar{Q})\mathbf{\Gamma}\)</span>: <span class="math display">\[\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 0 \\ 1 &amp; 1 \end{bmatrix} = \begin{bmatrix} (0)(0)+(1)(1)+(0)(0)+(1)(1) &amp; (0)(0)+(1)(0)+(0)(0)+(1)(1) \\ (0)(0)+(0)(1)+(0)(0)+(1)(1) &amp; (0)(0)+(0)(0)+(0)(0)+(1)(1) \end{bmatrix} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}\]</span> Finally, <span class="math inline">\(H = 2 \left( \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 1 \end{bmatrix} + \begin{bmatrix} 0.1 &amp; 0 \\ 0 &amp; 0.1 \end{bmatrix} \right) = 2 \begin{bmatrix} 2.1 &amp; 1 \\ 1 &amp; 1.1 \end{bmatrix} = \begin{bmatrix} 4.2 &amp; 2 \\ 2 &amp; 2.2 \end{bmatrix}\)</span></p>
<p>Now, let’s compute <span class="math inline">\(G\)</span> (assuming <span class="math inline">\(x_{ref}=0, u_{ref}=0\)</span>, so <span class="math inline">\(X_{ref}=0, U_{ref}=0\)</span>). In this case, <span class="math inline">\(G = 2\mathbf{\Gamma}^T \bar{Q} \mathbf{\Phi}x(k)\)</span>. Let <span class="math inline">\(x(k)=\begin{bmatrix} x_1 \\ x_2 \end{bmatrix}\)</span>.</p>
<p>First, <span class="math inline">\(\mathbf{\Phi}x(k)\)</span>: <span class="math display">\[\begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 0 \\ 2 &amp; 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} x_1 \\ x_1+x_2 \\ x_1 \\ 2x_1+x_2 \end{bmatrix}\]</span> Then, <span class="math inline">\(\bar{Q} \mathbf{\Phi}x(k)\)</span>: <span class="math display">\[\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_1+x_2 \\ x_1 \\ 2x_1+x_2 \end{bmatrix} = \begin{bmatrix} x_1 \\ x_1+x_2 \\ x_1 \\ 2x_1+x_2 \end{bmatrix}\]</span> Finally, <span class="math inline">\(G = 2\mathbf{\Gamma}^T (\bar{Q} \mathbf{\Phi}x(k))\)</span>: <span class="math display">\[G = 2 \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} x_1 \\ x_1+x_2 \\ x_1 \\ 2x_1+x_2 \end{bmatrix} = 2 \begin{bmatrix} (0)x_1 + (1)(x_1+x_2) + (0)x_1 + (1)(2x_1+x_2) \\ (0)x_1 + (0)(x_1+x_2) + (0)x_1 + (1)(2x_1+x_2) \end{bmatrix}\]</span> <span class="math display">\[G = 2 \begin{bmatrix} x_1+x_2 + 2x_1+x_2 \\ 2x_1+x_2 \end{bmatrix} = 2 \begin{bmatrix} 3x_1+2x_2 \\ 2x_1+x_2 \end{bmatrix} = \begin{bmatrix} 6x_1+4x_2 \\ 4x_1+2x_2 \end{bmatrix}\]</span></p>
<p>The <span class="math inline">\(J_{const}\)</span> term would be <span class="math inline">\(x(k)^T \mathbf{\Phi}^T \bar{Q} \mathbf{\Phi} x(k)\)</span>, which would be a scalar depending only on <span class="math inline">\(x(k)\)</span>.</p>
<p>This detailed breakdown shows how the matrices <span class="math inline">\(H\)</span> and <span class="math inline">\(G\)</span> are explicitly constructed from the system matrices, weights, and the current state. This allows a standard QP solver to take these numerical matrices and solve for the optimal <span class="math inline">\(U_k\)</span> sequence at each time step.</p>
</section>
</section>
<section id="but-why-do-we-need-to-transform-the-cost-function-into-separated-linear-quadratic-and-jconst-term" class="level3">
<h3 class="anchored" data-anchor-id="but-why-do-we-need-to-transform-the-cost-function-into-separated-linear-quadratic-and-jconst-term">But why do we need to transform the cost function into separated linear, quadratic and Jconst term?</h3>
<p>QP solvers are designed to solve problems in a very specific mathematical form. The standard general form of a Quadratic Program is:</p>
<p><strong>Minimize:</strong> <span class="math display">\[f(z) = \frac{1}{2} z^T H z + g^T z\]</span></p>
<p><strong>Subject to:</strong> <span class="math display">\[A_{eq} z = b_{eq}\]</span> <span class="math display">\[A_{ineq} z \le b_{ineq}\]</span></p>
<p>Where: * <span class="math inline">\(z\)</span> is the vector of optimization variables. * <span class="math inline">\(H\)</span> is the Hessian matrix (symmetric). It determines the curvature of the objective function. * <span class="math inline">\(g\)</span> is the linear term vector. * <span class="math inline">\(A_{eq}, b_{eq}, A_{ineq}, b_{ineq}\)</span> define the linear equality and inequality constraints.</p>
<p>By transforming the MPC objective into the form <span class="math inline">\(\frac{1}{2} U_k^T H U_k + G^T U_k + J_{const}\)</span>:</p>
<ul>
<li>Our decision variable <span class="math inline">\(U_k\)</span> maps directly to the generic <span class="math inline">\(z\)</span>.</li>
<li>Our calculated <span class="math inline">\(H\)</span> matrix maps directly to the generic <span class="math inline">\(H\)</span>.</li>
<li>Our calculated <span class="math inline">\(G\)</span> vector maps directly to the generic <span class="math inline">\(g\)</span>.</li>
</ul>



</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/tienthangdinh\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>